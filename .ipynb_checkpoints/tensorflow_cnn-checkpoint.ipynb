{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_convert(y):\n",
    "    onehot_y = np.zeros(number_of_classes)\n",
    "    onehot_y[y]=1  \n",
    "    return onehot_y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_image_to_tensor(file_name):\n",
    "    input_height=28\n",
    "    input_width=28\n",
    "    input_mean=128\n",
    "    input_std=128\n",
    "    \n",
    "    file_reader=tf.read_file(file_name)\n",
    "    image_reader = tf.image.decode_jpeg(file_reader, channels = 1,name='jpeg_reader')\n",
    "    float_caster = tf.cast(image_reader,tf.float32)\n",
    "    resized = tf.image.resize_images(float_caster,[input_height,input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # print(sess.run(tf.shape(normalized)))\n",
    "        return sess.run(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tensor_for_image(path1):\n",
    "\n",
    "    listing1 = os.listdir(path1)\n",
    "    train = []\n",
    "    label = []\n",
    "    class_number = -1\n",
    "    ext = ['jpeg','jpg','png']\n",
    "    # sess=tf.Session()\n",
    "    for file in listing1:\n",
    "        if(os.path.isdir(os.path.join(path1,file))):\n",
    "            class_number +=1\n",
    "            path2 = os.path.join(path1,file)\n",
    "            listing2 = os.listdir(path2)\n",
    "            for image in listing2:\n",
    "                if image.lower().endswith(tuple(ext)):\n",
    "                    file_name = os.path.join(path2,image)\n",
    "                    tensor = convert_image_to_tensor(file_name)\n",
    "                    train.append(tensor)\n",
    "                    onehot_label = one_hot_convert(class_number)\n",
    "                    label.append(onehot_label)\n",
    "                    # print(sess.run(tf.shape(tensor)))\n",
    "    # print(train) \n",
    "    return (np.array(train),np.array(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "# print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def cnn_graph(x):\n",
    "    \n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    # First Convolution Layer\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    # Second Convolution Layer\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    # Densely Connnected Layer\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # Dropout - Regularization Term for training larger neural network\n",
    "    # keep_prob = tf.placeholder(tf.float32)\n",
    "    # h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "    # Final Readout Layer\n",
    "    W_fc2 = weight_variable([1024, number_of_classes])\n",
    "    b_fc2 = bias_variable([number_of_classes])\n",
    "    y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "    \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_computation(y_conv):\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(\n",
    "                    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    saver = tf.train.Saver() \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(20):\n",
    "            sess.run(train_step,feed_dict={x:train, y_:labels})\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:train, y_:labels})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        saver.save(sess,'cats-dogs-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Directory Name : Pictures\n",
      "step 0, training accuracy 0.193211\n",
      "step 1, training accuracy 0.201044\n",
      "step 2, training accuracy 0.240209\n",
      "step 3, training accuracy 0.232376\n",
      "step 4, training accuracy 0.255875\n",
      "step 5, training accuracy 0.24282\n",
      "step 6, training accuracy 0.250653\n",
      "step 7, training accuracy 0.284595\n",
      "step 8, training accuracy 0.29765\n",
      "step 9, training accuracy 0.331593\n",
      "step 10, training accuracy 0.381201\n",
      "step 11, training accuracy 0.422976\n",
      "step 12, training accuracy 0.412533\n",
      "step 13, training accuracy 0.43342\n",
      "step 14, training accuracy 0.456919\n",
      "step 15, training accuracy 0.467363\n",
      "step 16, training accuracy 0.488251\n",
      "step 17, training accuracy 0.501305\n",
      "step 18, training accuracy 0.477807\n",
      "step 19, training accuracy 0.464752\n"
     ]
    }
   ],
   "source": [
    "# path_name = '/Users/ashu/Desktop/mlai/Pictures'\n",
    "path_name = \"\"\n",
    "path_name = raw_input(\"Image Directory Name : \")\n",
    "current_path = os.getcwd()\n",
    "path_name = os.path.join(current_path,path_name)\n",
    "number_of_classes = 0\n",
    "listing = os.listdir(path_name)\n",
    "for file in listing:\n",
    "        if(os.path.isdir(os.path.join(path_name,file))):\n",
    "            number_of_classes +=1\n",
    "train,labels = get_tensor_for_image(path_name)\n",
    "train = train.astype('float32')\n",
    "labels = labels.astype('float32')\n",
    "\n",
    "# labels=[]\n",
    "# for i in range(20):\n",
    "#     if i<10:\n",
    "#         labels.append([1,0])\n",
    "#     else:\n",
    "#         labels.append([0,1])\n",
    "# labels = np.array(labels)\n",
    "# labels = labels.astype('float32')\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,28,28,1],name=\"x\")\n",
    "y_= tf.placeholder(tf.float32,[None,number_of_classes],name=\"y_\")\n",
    "y_conv = cnn_graph(x)     \n",
    "y_pred = tf.nn.softmax(y_conv,name=\"y_pred\")\n",
    "cnn_computation(y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.39797936e-04   2.38120230e-03   1.41433235e-02   3.01094726e-03\n",
      "    9.80024755e-01]]\n"
     ]
    }
   ],
   "source": [
    "def get_prediction(target_image):\n",
    "\n",
    "    # target_image = '/Users/ashu/Desktop/mlai/cat.jpg'\n",
    "    image_tensor = convert_image_to_tensor(target_image)\n",
    "    images=[]\n",
    "    images.append(image_tensor)\n",
    "    images = np.array(images,dtype=np.uint8)\n",
    "    images = images.astype('float32')\n",
    "    # image_tensor = image_tensor.astype('float32')\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result=sess.run(y_pred, feed_dict={x:images})\n",
    "    # print(result)\n",
    "    return result\n",
    "\n",
    "result = get_prediction(os.path.join(os.getcwd(),\"cat.jpg\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_computation(train,labels):\n",
    "    logits = conn_graph(train,labels)\n",
    "    predictions = {\n",
    "        \"classes\" : tf.argmax(input=logits,axis=1),\n",
    "        \"probabilities\" : tf.nn.softmax(logits,name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # defining loss function\n",
    "    onehot_labels = tf.one_hot(indices=labels,depth=2)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels,logits=logits)\n",
    "    \n",
    "    # optimizing the loss/error function\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "    total_epoch=10\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(total_epoch):\n",
    "            epoch_loss,_ = sess.run([loss,train_op])\n",
    "            print(epoch,epoch_loss)\n",
    "#         accuracy =tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "#         print(accuracy)\n",
    "#         print('Accuracy = ', sess.run(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
